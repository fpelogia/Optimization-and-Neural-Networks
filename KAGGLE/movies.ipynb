{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "data = keras.datasets.imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = data.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = data.get_word_index()\n",
    "word_index = {k:(v+3) for k, v in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,289\n",
      "Trainable params: 160,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/fpelogia/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "15000/15000 [==============================] - 1s 56us/sample - loss: 0.6920 - accuracy: 0.5330 - val_loss: 0.6902 - val_accuracy: 0.5612\n",
      "Epoch 2/40\n",
      "15000/15000 [==============================] - 1s 40us/sample - loss: 0.6865 - accuracy: 0.6807 - val_loss: 0.6825 - val_accuracy: 0.7209\n",
      "Epoch 3/40\n",
      "15000/15000 [==============================] - 1s 41us/sample - loss: 0.6741 - accuracy: 0.7432 - val_loss: 0.6666 - val_accuracy: 0.7523\n",
      "Epoch 4/40\n",
      "15000/15000 [==============================] - 1s 41us/sample - loss: 0.6516 - accuracy: 0.7509 - val_loss: 0.6405 - val_accuracy: 0.7638\n",
      "Epoch 5/40\n",
      "15000/15000 [==============================] - 1s 42us/sample - loss: 0.6176 - accuracy: 0.7863 - val_loss: 0.6047 - val_accuracy: 0.7842\n",
      "Epoch 6/40\n",
      "15000/15000 [==============================] - 1s 40us/sample - loss: 0.5739 - accuracy: 0.8105 - val_loss: 0.5627 - val_accuracy: 0.8001\n",
      "Epoch 7/40\n",
      "15000/15000 [==============================] - 1s 43us/sample - loss: 0.5250 - accuracy: 0.8283 - val_loss: 0.5168 - val_accuracy: 0.8214\n",
      "Epoch 8/40\n",
      "15000/15000 [==============================] - 1s 45us/sample - loss: 0.4762 - accuracy: 0.8477 - val_loss: 0.4748 - val_accuracy: 0.8321\n",
      "Epoch 9/40\n",
      "15000/15000 [==============================] - 1s 40us/sample - loss: 0.4312 - accuracy: 0.8630 - val_loss: 0.4374 - val_accuracy: 0.8430\n",
      "Epoch 10/40\n",
      "15000/15000 [==============================] - 1s 39us/sample - loss: 0.3918 - accuracy: 0.8757 - val_loss: 0.4069 - val_accuracy: 0.8509\n",
      "Epoch 11/40\n",
      "15000/15000 [==============================] - 1s 39us/sample - loss: 0.3587 - accuracy: 0.8835 - val_loss: 0.3818 - val_accuracy: 0.8598\n",
      "Epoch 12/40\n",
      "15000/15000 [==============================] - 1s 39us/sample - loss: 0.3310 - accuracy: 0.8915 - val_loss: 0.3629 - val_accuracy: 0.8632\n",
      "Epoch 13/40\n",
      "15000/15000 [==============================] - 1s 40us/sample - loss: 0.3084 - accuracy: 0.8981 - val_loss: 0.3462 - val_accuracy: 0.8707\n",
      "Epoch 14/40\n",
      "15000/15000 [==============================] - 1s 41us/sample - loss: 0.2881 - accuracy: 0.9021 - val_loss: 0.3341 - val_accuracy: 0.8745\n",
      "Epoch 15/40\n",
      "15000/15000 [==============================] - 1s 40us/sample - loss: 0.2712 - accuracy: 0.9071 - val_loss: 0.3240 - val_accuracy: 0.8757\n",
      "Epoch 16/40\n",
      "15000/15000 [==============================] - 1s 41us/sample - loss: 0.2560 - accuracy: 0.9132 - val_loss: 0.3158 - val_accuracy: 0.8757\n",
      "Epoch 17/40\n",
      "15000/15000 [==============================] - 1s 40us/sample - loss: 0.2419 - accuracy: 0.9177 - val_loss: 0.3089 - val_accuracy: 0.8798\n",
      "Epoch 18/40\n",
      "15000/15000 [==============================] - 1s 43us/sample - loss: 0.2295 - accuracy: 0.9216 - val_loss: 0.3031 - val_accuracy: 0.8803\n",
      "Epoch 19/40\n",
      "15000/15000 [==============================] - 1s 45us/sample - loss: 0.2183 - accuracy: 0.9237 - val_loss: 0.2983 - val_accuracy: 0.8817\n",
      "Epoch 20/40\n",
      "15000/15000 [==============================] - 1s 40us/sample - loss: 0.2082 - accuracy: 0.9279 - val_loss: 0.2951 - val_accuracy: 0.8828\n",
      "Epoch 21/40\n",
      "15000/15000 [==============================] - 1s 43us/sample - loss: 0.1979 - accuracy: 0.9334 - val_loss: 0.2923 - val_accuracy: 0.8833\n",
      "Epoch 22/40\n",
      "15000/15000 [==============================] - 1s 42us/sample - loss: 0.1893 - accuracy: 0.9371 - val_loss: 0.2896 - val_accuracy: 0.8850\n",
      "Epoch 23/40\n",
      "15000/15000 [==============================] - 1s 39us/sample - loss: 0.1805 - accuracy: 0.9413 - val_loss: 0.2888 - val_accuracy: 0.8838\n",
      "Epoch 24/40\n",
      "15000/15000 [==============================] - 1s 38us/sample - loss: 0.1730 - accuracy: 0.9451 - val_loss: 0.2877 - val_accuracy: 0.8848\n",
      "Epoch 25/40\n",
      "15000/15000 [==============================] - 1s 43us/sample - loss: 0.1653 - accuracy: 0.9475 - val_loss: 0.2861 - val_accuracy: 0.8855\n",
      "Epoch 26/40\n",
      "15000/15000 [==============================] - 1s 39us/sample - loss: 0.1584 - accuracy: 0.9499 - val_loss: 0.2871 - val_accuracy: 0.8843\n",
      "Epoch 27/40\n",
      "15000/15000 [==============================] - 1s 38us/sample - loss: 0.1519 - accuracy: 0.9530 - val_loss: 0.2867 - val_accuracy: 0.8853\n",
      "Epoch 28/40\n",
      "15000/15000 [==============================] - 1s 41us/sample - loss: 0.1456 - accuracy: 0.9555 - val_loss: 0.2877 - val_accuracy: 0.8849\n",
      "Epoch 29/40\n",
      "15000/15000 [==============================] - 1s 41us/sample - loss: 0.1402 - accuracy: 0.9583 - val_loss: 0.2891 - val_accuracy: 0.8845\n",
      "Epoch 30/40\n",
      "15000/15000 [==============================] - 1s 42us/sample - loss: 0.1345 - accuracy: 0.9590 - val_loss: 0.2888 - val_accuracy: 0.8866\n",
      "Epoch 31/40\n",
      "15000/15000 [==============================] - 1s 39us/sample - loss: 0.1285 - accuracy: 0.9626 - val_loss: 0.2900 - val_accuracy: 0.8857\n",
      "Epoch 32/40\n",
      "15000/15000 [==============================] - 1s 40us/sample - loss: 0.1234 - accuracy: 0.9649 - val_loss: 0.2917 - val_accuracy: 0.8867\n",
      "Epoch 33/40\n",
      "15000/15000 [==============================] - 1s 61us/sample - loss: 0.1184 - accuracy: 0.9670 - val_loss: 0.2942 - val_accuracy: 0.8866\n",
      "Epoch 34/40\n",
      "15000/15000 [==============================] - 1s 64us/sample - loss: 0.1140 - accuracy: 0.9676 - val_loss: 0.2967 - val_accuracy: 0.8861\n",
      "Epoch 35/40\n",
      "15000/15000 [==============================] - 1s 60us/sample - loss: 0.1097 - accuracy: 0.9693 - val_loss: 0.2988 - val_accuracy: 0.8848\n",
      "Epoch 36/40\n",
      "15000/15000 [==============================] - 1s 64us/sample - loss: 0.1053 - accuracy: 0.9709 - val_loss: 0.3010 - val_accuracy: 0.8840\n",
      "Epoch 37/40\n",
      "15000/15000 [==============================] - 1s 56us/sample - loss: 0.1010 - accuracy: 0.9735 - val_loss: 0.3040 - val_accuracy: 0.8853\n",
      "Epoch 38/40\n",
      "15000/15000 [==============================] - 1s 67us/sample - loss: 0.0970 - accuracy: 0.9745 - val_loss: 0.3077 - val_accuracy: 0.8832\n",
      "Epoch 39/40\n",
      "15000/15000 [==============================] - 1s 57us/sample - loss: 0.0938 - accuracy: 0.9760 - val_loss: 0.3119 - val_accuracy: 0.8831\n",
      "Epoch 40/40\n",
      "15000/15000 [==============================] - 1s 66us/sample - loss: 0.0897 - accuracy: 0.9784 - val_loss: 0.3148 - val_accuracy: 0.8831\n",
      "25000/25000 [==============================] - 2s 65us/sample - loss: 0.3374 - accuracy: 0.8692\n",
      "[0.3374414035511017, 0.86916]\n"
     ]
    }
   ],
   "source": [
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data, value=word_index[\"<PAD>\"], padding = \"post\", maxlen=250)\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data, value=word_index[\"<PAD>\"], padding = \"post\", maxlen=250)\n",
    "\n",
    "def decode_review(text):\n",
    "    return \" \".join([reverse_word_index.get(i, \"?\") for i in text])\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(10000, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    " \n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "x_val = train_data[:10000]\n",
    "x_train = train_data[10000:]\n",
    "\n",
    "y_val = train_labels[:10000]\n",
    "y_train = train_labels[10000:]\n",
    "\n",
    "fitModel = model.fit(x_train, y_train, epochs=40, batch_size=512, validation_data=(x_val, y_val), verbose=1)\n",
    "\n",
    "results = model.evaluate(test_data, test_labels)\n",
    "\n",
    "print(results)\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: \n",
      "<UNK> the second circle a young man returns to the russian countryside to bury his deceased father in the shack where the old man once lived everything is covered with dust he <UNK> the few old clothes scattered around and places the body of his father in a coffin then he <UNK> goodbye and <UNK> it the rest of the film is a prolonged reflection on the collapse of the soviet system the loneliness and <UNK> many were left dealing with br br in modern love somewhat ironically love is nowhere to be seen on the contrary it is pain loneliness and <UNK> with <UNK> that suddenly <UNK> john's life unlike the second circle however here the main protagonist has the opportunity to re embrace his modern life his wife and son <UNK> him yet he walks away slowly but surely the present begins to <UNK> under the weight of a somewhat confusing past br br i doubt intended for modern love to be so strikingly similar to what <UNK> did in the second circle yet the pacing and in particular the puzzling framing are precisely what transforms this film into a near <UNK> experience a difficult and enormously <UNK> approach to <UNK> human psychology the two directors have <UNK> to perfection br br mark <UNK> delivers a top notch performance as john adding even greater depth to his highly challenging character his facial expressions are outstanding both victoria hill and william match perfectly with their performances tense visual style\n",
      "Prediction: [0.99999255]\n",
      "Actual: 1\n"
     ]
    }
   ],
   "source": [
    "test_review = test_data[44]\n",
    "predict = model.predict([test_review])\n",
    "print(\"Review: \")\n",
    "print(decode_review(test_review))\n",
    "print(\"Prediction: \" + str(predict[44]))\n",
    "print(\"Actual: \" + str(test_labels[44]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": " indices[0,10] = 12873 is not in [0, 10000)\n\t [[node embedding_1/embedding_lookup (defined at <ipython-input-25-4ad972743761>:16) ]] [Op:__inference_keras_scratch_graph_20211]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-4ad972743761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mencode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mencode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<PAD>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m         callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3508\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3509\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3510\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3512\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    570\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    571\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 572\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    443\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    444\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 445\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    446\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  indices[0,10] = 12873 is not in [0, 10000)\n\t [[node embedding_1/embedding_lookup (defined at <ipython-input-25-4ad972743761>:16) ]] [Op:__inference_keras_scratch_graph_20211]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def review_encode(s):\n",
    "    encoded = [1]\n",
    "    \n",
    "    for word in s:\n",
    "        if word.lower() in word_index:\n",
    "            encoded.append(word_index[word.lower()])\n",
    "        else:\n",
    "            encoded.append(2)\n",
    "    return encoded\n",
    "\n",
    "with open(\"sw8.txt\", encoding=\"utf-8\") as f:\n",
    "    for line in f.readlines():\n",
    "        nline = line.replace(\",\",\"\").replace(\".\",\"\").replace(\"(\",\"\").replace(\")\",\"\").replace(\":\",\"\").replace(\"\\\"\",\"\").strip().split(\" \")\n",
    "        encode = review_encode(nline)\n",
    "        encode = keras.preprocessing.sequence.pad_sequences([encode], value=word_index[\"<PAD>\"], padding = \"post\", maxlen=250)\n",
    "        predict = model.predict(encode)\n",
    "        print(line)\n",
    "        print(encode)\n",
    "        print(predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
