{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "data = keras.datasets.imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = data.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = data.get_word_index()\n",
    "word_index = {k:(v+3) for k, v in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,289\n",
      "Trainable params: 160,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/fpelogia/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "15000/15000 [==============================] - 1s 56us/sample - loss: 0.6920 - accuracy: 0.5330 - val_loss: 0.6902 - val_accuracy: 0.5612\n",
      "Epoch 2/40\n",
      "15000/15000 [==============================] - 1s 40us/sample - loss: 0.6865 - accuracy: 0.6807 - val_loss: 0.6825 - val_accuracy: 0.7209\n",
      "Epoch 3/40\n",
      "15000/15000 [==============================] - 1s 41us/sample - loss: 0.6741 - accuracy: 0.7432 - val_loss: 0.6666 - val_accuracy: 0.7523\n",
      "Epoch 4/40\n",
      "15000/15000 [==============================] - 1s 41us/sample - loss: 0.6516 - accuracy: 0.7509 - val_loss: 0.6405 - val_accuracy: 0.7638\n",
      "Epoch 5/40\n",
      "15000/15000 [==============================] - 1s 42us/sample - loss: 0.6176 - accuracy: 0.7863 - val_loss: 0.6047 - val_accuracy: 0.7842\n",
      "Epoch 6/40\n",
      "15000/15000 [==============================] - 1s 40us/sample - loss: 0.5739 - accuracy: 0.8105 - val_loss: 0.5627 - val_accuracy: 0.8001\n",
      "Epoch 7/40\n",
      "15000/15000 [==============================] - 1s 43us/sample - loss: 0.5250 - accuracy: 0.8283 - val_loss: 0.5168 - val_accuracy: 0.8214\n",
      "Epoch 8/40\n",
      "15000/15000 [==============================] - 1s 45us/sample - loss: 0.4762 - accuracy: 0.8477 - val_loss: 0.4748 - val_accuracy: 0.8321\n",
      "Epoch 9/40\n",
      "15000/15000 [==============================] - 1s 40us/sample - loss: 0.4312 - accuracy: 0.8630 - val_loss: 0.4374 - val_accuracy: 0.8430\n",
      "Epoch 10/40\n",
      "15000/15000 [==============================] - 1s 39us/sample - loss: 0.3918 - accuracy: 0.8757 - val_loss: 0.4069 - val_accuracy: 0.8509\n",
      "Epoch 11/40\n",
      "15000/15000 [==============================] - 1s 39us/sample - loss: 0.3587 - accuracy: 0.8835 - val_loss: 0.3818 - val_accuracy: 0.8598\n",
      "Epoch 12/40\n",
      "15000/15000 [==============================] - 1s 39us/sample - loss: 0.3310 - accuracy: 0.8915 - val_loss: 0.3629 - val_accuracy: 0.8632\n",
      "Epoch 13/40\n",
      "15000/15000 [==============================] - 1s 40us/sample - loss: 0.3084 - accuracy: 0.8981 - val_loss: 0.3462 - val_accuracy: 0.8707\n",
      "Epoch 14/40\n",
      "15000/15000 [==============================] - 1s 41us/sample - loss: 0.2881 - accuracy: 0.9021 - val_loss: 0.3341 - val_accuracy: 0.8745\n",
      "Epoch 15/40\n",
      "15000/15000 [==============================] - 1s 40us/sample - loss: 0.2712 - accuracy: 0.9071 - val_loss: 0.3240 - val_accuracy: 0.8757\n",
      "Epoch 16/40\n",
      "15000/15000 [==============================] - 1s 41us/sample - loss: 0.2560 - accuracy: 0.9132 - val_loss: 0.3158 - val_accuracy: 0.8757\n",
      "Epoch 17/40\n",
      "15000/15000 [==============================] - 1s 40us/sample - loss: 0.2419 - accuracy: 0.9177 - val_loss: 0.3089 - val_accuracy: 0.8798\n",
      "Epoch 18/40\n",
      "15000/15000 [==============================] - 1s 43us/sample - loss: 0.2295 - accuracy: 0.9216 - val_loss: 0.3031 - val_accuracy: 0.8803\n",
      "Epoch 19/40\n",
      "15000/15000 [==============================] - 1s 45us/sample - loss: 0.2183 - accuracy: 0.9237 - val_loss: 0.2983 - val_accuracy: 0.8817\n",
      "Epoch 20/40\n",
      "15000/15000 [==============================] - 1s 40us/sample - loss: 0.2082 - accuracy: 0.9279 - val_loss: 0.2951 - val_accuracy: 0.8828\n",
      "Epoch 21/40\n",
      "15000/15000 [==============================] - 1s 43us/sample - loss: 0.1979 - accuracy: 0.9334 - val_loss: 0.2923 - val_accuracy: 0.8833\n",
      "Epoch 22/40\n",
      "15000/15000 [==============================] - 1s 42us/sample - loss: 0.1893 - accuracy: 0.9371 - val_loss: 0.2896 - val_accuracy: 0.8850\n",
      "Epoch 23/40\n",
      "15000/15000 [==============================] - 1s 39us/sample - loss: 0.1805 - accuracy: 0.9413 - val_loss: 0.2888 - val_accuracy: 0.8838\n",
      "Epoch 24/40\n",
      "15000/15000 [==============================] - 1s 38us/sample - loss: 0.1730 - accuracy: 0.9451 - val_loss: 0.2877 - val_accuracy: 0.8848\n",
      "Epoch 25/40\n",
      "15000/15000 [==============================] - 1s 43us/sample - loss: 0.1653 - accuracy: 0.9475 - val_loss: 0.2861 - val_accuracy: 0.8855\n",
      "Epoch 26/40\n",
      "15000/15000 [==============================] - 1s 39us/sample - loss: 0.1584 - accuracy: 0.9499 - val_loss: 0.2871 - val_accuracy: 0.8843\n",
      "Epoch 27/40\n",
      "15000/15000 [==============================] - 1s 38us/sample - loss: 0.1519 - accuracy: 0.9530 - val_loss: 0.2867 - val_accuracy: 0.8853\n",
      "Epoch 28/40\n",
      "15000/15000 [==============================] - 1s 41us/sample - loss: 0.1456 - accuracy: 0.9555 - val_loss: 0.2877 - val_accuracy: 0.8849\n",
      "Epoch 29/40\n",
      "15000/15000 [==============================] - 1s 41us/sample - loss: 0.1402 - accuracy: 0.9583 - val_loss: 0.2891 - val_accuracy: 0.8845\n",
      "Epoch 30/40\n",
      "15000/15000 [==============================] - 1s 42us/sample - loss: 0.1345 - accuracy: 0.9590 - val_loss: 0.2888 - val_accuracy: 0.8866\n",
      "Epoch 31/40\n",
      "15000/15000 [==============================] - 1s 39us/sample - loss: 0.1285 - accuracy: 0.9626 - val_loss: 0.2900 - val_accuracy: 0.8857\n",
      "Epoch 32/40\n",
      "15000/15000 [==============================] - 1s 40us/sample - loss: 0.1234 - accuracy: 0.9649 - val_loss: 0.2917 - val_accuracy: 0.8867\n",
      "Epoch 33/40\n",
      "15000/15000 [==============================] - 1s 61us/sample - loss: 0.1184 - accuracy: 0.9670 - val_loss: 0.2942 - val_accuracy: 0.8866\n",
      "Epoch 34/40\n",
      "15000/15000 [==============================] - 1s 64us/sample - loss: 0.1140 - accuracy: 0.9676 - val_loss: 0.2967 - val_accuracy: 0.8861\n",
      "Epoch 35/40\n",
      "15000/15000 [==============================] - 1s 60us/sample - loss: 0.1097 - accuracy: 0.9693 - val_loss: 0.2988 - val_accuracy: 0.8848\n",
      "Epoch 36/40\n",
      "15000/15000 [==============================] - 1s 64us/sample - loss: 0.1053 - accuracy: 0.9709 - val_loss: 0.3010 - val_accuracy: 0.8840\n",
      "Epoch 37/40\n",
      "15000/15000 [==============================] - 1s 56us/sample - loss: 0.1010 - accuracy: 0.9735 - val_loss: 0.3040 - val_accuracy: 0.8853\n",
      "Epoch 38/40\n",
      "15000/15000 [==============================] - 1s 67us/sample - loss: 0.0970 - accuracy: 0.9745 - val_loss: 0.3077 - val_accuracy: 0.8832\n",
      "Epoch 39/40\n",
      "15000/15000 [==============================] - 1s 57us/sample - loss: 0.0938 - accuracy: 0.9760 - val_loss: 0.3119 - val_accuracy: 0.8831\n",
      "Epoch 40/40\n",
      "15000/15000 [==============================] - 1s 66us/sample - loss: 0.0897 - accuracy: 0.9784 - val_loss: 0.3148 - val_accuracy: 0.8831\n",
      "25000/25000 [==============================] - 2s 65us/sample - loss: 0.3374 - accuracy: 0.8692\n",
      "[0.3374414035511017, 0.86916]\n"
     ]
    }
   ],
   "source": [
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data, value=word_index[\"<PAD>\"], padding = \"post\", maxlen=250)\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data, value=word_index[\"<PAD>\"], padding = \"post\", maxlen=250)\n",
    "\n",
    "def decode_review(text):\n",
    "    return \" \".join([reverse_word_index.get(i, \"?\") for i in text])\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(10000, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    " \n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "x_val = train_data[:10000]\n",
    "x_train = train_data[10000:]\n",
    "\n",
    "y_val = train_labels[:10000]\n",
    "y_train = train_labels[10000:]\n",
    "\n",
    "fitModel = model.fit(x_train, y_train, epochs=40, batch_size=512, validation_data=(x_val, y_val), verbose=1)\n",
    "\n",
    "results = model.evaluate(test_data, test_labels)\n",
    "\n",
    "print(results)\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: \n",
      "<UNK> the second circle a young man returns to the russian countryside to bury his deceased father in the shack where the old man once lived everything is covered with dust he <UNK> the few old clothes scattered around and places the body of his father in a coffin then he <UNK> goodbye and <UNK> it the rest of the film is a prolonged reflection on the collapse of the soviet system the loneliness and <UNK> many were left dealing with br br in modern love somewhat ironically love is nowhere to be seen on the contrary it is pain loneliness and <UNK> with <UNK> that suddenly <UNK> john's life unlike the second circle however here the main protagonist has the opportunity to re embrace his modern life his wife and son <UNK> him yet he walks away slowly but surely the present begins to <UNK> under the weight of a somewhat confusing past br br i doubt intended for modern love to be so strikingly similar to what <UNK> did in the second circle yet the pacing and in particular the puzzling framing are precisely what transforms this film into a near <UNK> experience a difficult and enormously <UNK> approach to <UNK> human psychology the two directors have <UNK> to perfection br br mark <UNK> delivers a top notch performance as john adding even greater depth to his highly challenging character his facial expressions are outstanding both victoria hill and william match perfectly with their performances tense visual style\n",
      "Prediction: [0.99999255]\n",
      "Actual: 1\n"
     ]
    }
   ],
   "source": [
    "test_review = test_data[44]\n",
    "predict = model.predict([test_review])\n",
    "print(\"Review: \")\n",
    "print(decode_review(test_review))\n",
    "print(\"Prediction: \" + str(predict[44]))\n",
    "print(\"Actual: \" + str(test_labels[44]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def review_encode(s):\n",
    "    encoded = [1]\n",
    "    \n",
    "    for word in s:\n",
    "        if word.lower() in word_index:\n",
    "            encoded.append(word_index[word])\n",
    "        else:\n",
    "            encoded.append(2)\n",
    "\n",
    "with open(\"sw8.txt\", encoding=\"utf-8\") as f:\n",
    "    for line in f.readlines():\n",
    "        nline = line.replace(\",\",\"\").replace(\".\",\"\").replace(\"(\",\"\").replace(\")\",\"\").replace(\":\",\"\").replace(\"\\\"\",\"\").strip().split(\" \")\n",
    "        encode = review_encode(nline)\n",
    "        encode = keras.preprocessing.sequence.pad_sequences([encode], value=word_index[\"<PAD>\"], padding = \"post\", maxlen=250)\n",
    "        predict = model.predict(encode)\n",
    "        print(line)\n",
    "        print(encode)\n",
    "        print(predict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
