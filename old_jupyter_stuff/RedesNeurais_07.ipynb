{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RedesNeurais_07.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "-2zlu2G1AIF6"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fpelogia/Optimization-and-Neural-Networks/blob/master/RedesNeurais_07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2zlu2G1AIF6",
        "colab_type": "text"
      },
      "source": [
        "#Redes Neurais\n",
        "[Voltar](https://colab.research.google.com/drive/1zGxVatpjlZtdtECAikT1eKP7EQ50m-Ur)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpPAZJs0hrvN",
        "colab_type": "text"
      },
      "source": [
        "#7 - Aumentando o número de camadas ocultas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuiwJNEzAPrU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy import linalg as la \n",
        "%matplotlib inline\n",
        "\n",
        "epsilon = 0.0001\n",
        "\n",
        "def reLu(x):\n",
        "    return 0.5*(x + np.sqrt(x**2 + epsilon))\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1/(1+np.exp(-1*x)) \n",
        "\n",
        "class Layer():\n",
        "    def __init__(self, n_values, func = \"none\"):\n",
        "        self.n_values = n_values\n",
        "        self.func = func\n",
        "        self.arr = np.random.randn(n_values)\n",
        "        self.biases = np.random.randn(n_values)\n",
        "\n",
        "    \n",
        "class NeuralNetwork():\n",
        "  \n",
        "    def __init__(self, layers, learning_rate = 0.0005 ,optimizer = \"backpropagation\"):\n",
        "        self.layers = layers\n",
        "        self.n_layers = len(layers)\n",
        "        self.optimizer = optimizer\n",
        "        self.learning_rate = learning_rate\n",
        "        #inicializa as matrizes com os pesos\n",
        "        for i in range(len(self.layers) - 1):\n",
        "            n_curr = self.layers[i].n_values\n",
        "            n_next = self.layers[i+1].n_values\n",
        "            self.layers[i].weights = np.random.randn(n_curr,n_next)\n",
        "\n",
        "    def train_step(self, input, target):\n",
        "\n",
        "        self.layers[0].arr = input\n",
        "\n",
        "\n",
        "        # Feed-Forward\n",
        "        for i in range(self.n_layers):\n",
        "            \n",
        "            if i!= 0:\n",
        "                self.layers[i].arr = np.dot(self.layers[i-1].arr, self.layers[i-1].weights)        \n",
        "                self.layers[i].arr = np.add(self.layers[i].arr, self.layers[i].biases)\n",
        "                \n",
        "                if self.layers[i].func == \"sigmoid\":\n",
        "                    for j in range(self.layers[i].n_values):\n",
        "                        self.layers[i].arr[0][j] = sigmoid(self.layers[i].arr[0][j]) \n",
        "                elif self.layers[i].func == \"relu\":\n",
        "                    for j in range(self.layers[i].n_values):\n",
        "                        self.layers[i].arr[0][j] = reLu(self.layers[i].arr[0][j]) \n",
        "                else:\n",
        "                    if not self.layers[i].func == \"linear\":\n",
        "                        print(\"ERROR: unknown activation function {}\".format(self.layers[i].func))\n",
        "\n",
        "        output = self.layers[self.n_layers-1].arr\n",
        "\n",
        "        # Otimização\n",
        "   \n",
        "        if self.optimizer == \"backpropagation\":\n",
        "\n",
        "            for i in range(self.n_layers-1,0,-1):\n",
        "                if i == self.n_layers-1:\n",
        "                    error = target - output\n",
        "                else:\n",
        "                    error = np.dot(error, np.transpose(self.layers[i].weights))\n",
        "\n",
        "                if self.layers[i].func == \"linear\":\n",
        "                    d_func = 1\n",
        "                elif self.layers[i].func == \"sigmoid\":\n",
        "                    d_func = self.layers[i].arr*(1 - self.layers[i].arr)\n",
        "                elif self.layers[i].func == \"relu\":\n",
        "                    d_func = 0.5*(self.layers[i].arr/np.sqrt(self.layers[i].arr**2 + epsilon) + 1)\n",
        "                else:\n",
        "                    print(\"ERROR: unknown activation function {}\".format(self.layers[self.n_layers - 1].func))\n",
        "\n",
        "                gradient = self.learning_rate * error * d_func\n",
        "                \n",
        "                \n",
        "                self.layers[i].biases = np.add(self.layers[i].biases, gradient)\n",
        "\n",
        "                weights_deltas = np.dot(np.transpose(self.layers[i-1].arr), gradient)\n",
        "                \n",
        "                self.layers[i-1].weights = np.add(self.layers[i-1].weights, weights_deltas)\n",
        "        # IMPLEMENTAR PARA MÉTODO DO GRADIENTE TBM\n",
        "\n",
        "    def predict(self, input):\n",
        "\n",
        "        self.layers[0].arr = input\n",
        "\n",
        "        # Feed-Forward\n",
        "        for i in range(len(self.layers)):\n",
        "            if i!= 0:\n",
        "                self.layers[i].arr = np.dot(self.layers[i-1].arr, self.layers[i-1].weights)        \n",
        "                self.layers[i].arr = np.add(self.layers[i].arr, self.layers[i].biases)\n",
        "                \n",
        "                if self.layers[i].func == \"sigmoid\":\n",
        "                    for j in range(self.layers[i].n_values):\n",
        "                        self.layers[i].arr[0][j] = sigmoid(self.layers[i].arr[0][j]) \n",
        "                elif self.layers[i].func == \"relu\":\n",
        "                    for j in range(self.layers[i].n_values):\n",
        "                        self.layers[i].arr[0][j] = reLu(self.layers[i].arr[0][j]) \n",
        "                else:\n",
        "                    if not self.layers[i].func == \"linear\":\n",
        "                        print(\"ERROR: unknown activation function {}\".format(self.layers[i].func))\n",
        "\n",
        "        output = self.layers[self.n_layers-1].arr\n",
        "        return output\n",
        "    \n",
        "    \n",
        "    def train(self, trainning_set, labels, epochs=1000):\n",
        "        for _ in range(epochs):\n",
        "            index  = np.random.randint(len(trainning_set))\n",
        "            self.train_step(trainning_set[index], labels[index]) \n",
        "            \n",
        "    def train2(self, X, y,ep = 1000):\n",
        "        for i in range(ep):\n",
        "          for j in range(len(X)):\n",
        "            self.train_step(X[j], y[j])\n",
        "    \n",
        "            \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3zluayLALJ5",
        "colab_type": "text"
      },
      "source": [
        "##7.1 - Duas camadas ocultas\n",
        "![rede](https://drive.google.com/uc?id=1yfezKD8NpPxqYm8XH7wCkh77jyIvI9sN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qQk2QI1-CIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "layers = [Layer(1), Layer(2,\"relu\"), Layer(2,\"relu\"),Layer(1,\"linear\")]\n",
        "X = np.array([1.0, 2.0, 3.0, 4.0, 5.0])\n",
        "y = X**2\n",
        "\n",
        "mynn = NeuralNetwork(layers, 0.0001, optimizer= \"backpropagation\")\n",
        "mynn.train2(X, y)\n",
        "\n",
        "ex = np.linspace(0,100,100)\n",
        "ey = [mynn.predict(val)[0] for val in ex]\n",
        "\n",
        "\n",
        "    \n",
        "plt.axis([0,10,0,30])\n",
        "\n",
        "\n",
        "plt.scatter(X,y,s = 30, c = \"red\")\n",
        "plt.plot(ex,ey)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YebZ1qbH5LVL",
        "colab_type": "text"
      },
      "source": [
        "#TESTES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2cpEnrn5O7E",
        "colab_type": "code",
        "outputId": "bbdb9c77-f673-4aa9-d732-6d184da53f69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "\n",
        "\n",
        "layers = [Layer(1), Layer(2,\"relu\"), Layer(2,\"relu\"),Layer(2,\"relu\"),Layer(1,\"relu\")]\n",
        "X = np.array([1.0, 2.0, 3.0, 4.0, 5.0])\n",
        "y = X**2\n",
        "\n",
        "mynn = NeuralNetwork(layers, 0.0001, optimizer= \"backpropagation\")\n",
        "mynn.train(X, y, 10000)\n",
        "\n",
        "ex = np.linspace(0,100,100)\n",
        "ey = [mynn.predict(val)[0] for val in ex]\n",
        "\n",
        "\n",
        "    \n",
        "plt.axis([0,10,0,30])\n",
        "\n",
        "\n",
        "plt.scatter(X,y,s = 30, c = \"red\")\n",
        "plt.plot(ex,ey)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5c84d077f0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlbuISAxSuYuIxCCVu4hIDFK5i4jEoP8PAY87pKfErJsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}
